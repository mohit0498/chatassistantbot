import os
import time
import textwrap

from functools import wraps
from typing import Callable, Any


def remove_file(path_to_file: str) -> None:
    """
    Remove file if exists
    Args:
        path_to_file: full path to file
    """
    try:
        if os.path.exists(path_to_file):
            os.remove(path_to_file)
    except OSError:
        pass


def output_response(response: str) -> None:
    """
    You may be wondering why aren't we streaming the response using the openai completion API
    This is currently in beta in the langchain library, I will update this example
    to showcase this as implementation details may change
    Since it's flagged as beta adding it here may cause confusion as most
    likely it will be changed again within a few weeks
    For now output_response will simulate streaming for the purpose of illustration

    Args:
        response: text output generated by ChatGPT
    """
    if not response:
        exit(0)
    for line in textwrap.wrap(response, width=75):
        for word in line.split():
            for char in word:
                print(char, end='', flush=True)
                time.sleep(0.01)  # Add a delay of 0.1 seconds between each character
            print(' ', end='', flush=True)  # Add a space between each word
        print()  # Move to the next line after each line is printed
    print("-----")


def timeit(func: Callable[..., Any]) -> Callable[..., Any]:
    @wraps(func)
    def timeit_call(*args: Any, **kwargs: Any) -> Any:
        start_time = time.perf_counter()
        result = func(*args, **kwargs)
        end_time = time.perf_counter()
        total_time = end_time - start_time
        print(f'Function {func.__name__}{args} {kwargs} Took {total_time:.4f} seconds')
        return result
    return timeit_call
